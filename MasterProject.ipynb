{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH Algorithm Improvement By Applying Bitmap Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import scipy as sp\n",
    "import numpy as np # Import numpy library \n",
    "from sklearn.model_selection import StratifiedKFold #Import stratified kfold as we are using a 10fold cross validation approach\n",
    "from skimage.feature import hog # Import Hog model to extract features\n",
    "from sklearn.metrics import confusion_matrix # Import confusion matrix to evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "file_size = []\n",
    "k = 0\n",
    "path = \"./data/101_ObjectCategories\" # Give the dataset path here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preprocessing:\n",
    "1. Load the images using cv2\n",
    "2. Image resize\n",
    "3. Feature extraction: BGR to Gray conversion \n",
    "4. Feature extraction: Histogram of Oriented Gradients(HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.listdir(path) # from the given path get the file names such as accordion, airplanes etc..\n",
    "for file in folder: # for every file name in the given path go inseide that directory and get the images\n",
    "    subpath = os.path.join(path,file)  # Join the name of these files to the previous path \n",
    "    \n",
    "    files = os.listdir(subpath) # Take these image names to a list called files\n",
    "    j = 0\n",
    "    for i in range(np.size(files)): # now we shall loop through these number of files\n",
    "        \n",
    "        im = cv2.imread(subpath+'/'+files[0+j]) # Read the images from this subpath\n",
    "        \n",
    "        imgs.append(im) # append all the read images to a list called imgs\n",
    "        labels.append(k) # generate a labe to every file and append it to labels list\n",
    "\n",
    "        j += 1\n",
    "        if (j == (np.size(files))):\n",
    "            file_size.append(j)\n",
    "   \n",
    "    k += 1\n",
    "     \n",
    "labels = np.array(y).tolist()\n",
    "ix = []\n",
    "for index, item in enumerate(imgs):\n",
    "    if (np.size(item) == 1):\n",
    "        ix.append(index)\n",
    "        del imgs[index]\n",
    "        \n",
    "for index, item in enumerate(y):\n",
    "    for v in range(np.size(ix)):\n",
    "        if (index == ix[v]):\n",
    "            del y[index]\n",
    "        \n",
    "labels = np.array(y).astype(np.float64) \n",
    "\n",
    "# Function to convert an image from color to grayscale\n",
    "def rgb2gray(rgb):\n",
    "    gray = cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def resize_(image):\n",
    "    u = cv2.resize(image,(256,256))\n",
    "    return u\n",
    "\n",
    "def fd_hog(image):\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(64, 64),\n",
    "                    cells_per_block=(1, 1), visualize=True)\n",
    "    \n",
    "    return fd\n",
    "\n",
    "a=[]\n",
    "for img in imgs:\n",
    "    \n",
    "    b=resize_(img)\n",
    "    c=rgb2gray(b)   \n",
    "    d=fd_hog(c)\n",
    "    a.append(d)\n",
    "\n",
    "a=np.array(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "Split the data to training and validation data. We choose 70% for training and 30% for validation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append 'label' and 'id' to the last two colunms\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(a)\n",
    "df['lable'] = labels\n",
    "id_ = np.arange(1,len(df)+1,1)\n",
    "df['id'] = id_\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PySpark to retrieve similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinHashLSH\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "     .master(\"local\") \\\n",
    "     .appName(\"Image Retrieval\") \\\n",
    "     .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = map(lambda x: (int(x[-1]),int(x[-2]),Vectors.dense(x[:-2])), X_train)\n",
    "Train_df = spark.createDataFrame(Train,schema=['id','label',\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = map(lambda x: (int(x[-1]),int(x[-2]),Vectors.dense(x[:-2])), X_test)\n",
    "Test_df = spark.createDataFrame(Test,schema=['id','label',\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "brp = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", bucketLength=2.0,numHashTables=3)\n",
    "model = brp.fit(Train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hashed dataset where hashed values are stored in the column 'hashes':\n",
      "+----+-----+--------------------+--------------------+\n",
      "|  id|label|            features|              hashes|\n",
      "+----+-----+--------------------+--------------------+\n",
      "|2011|   21|[0.0,0.0,0.0,0.0,...|[[-1.0], [0.0], [...|\n",
      "|3355|   44|[0.0,0.0,0.0,0.0,...|[[-1.0], [-1.0], ...|\n",
      "|4986|   65|[0.22930449974017...|[[-1.0], [0.0], [...|\n",
      "|4829|   64|[0.34324529743848...|[[-1.0], [0.0], [...|\n",
      "|6084|   82|[0.23114755083290...|[[-1.0], [0.0], [...|\n",
      "|1554|   18|[0.75324468396522...|[[-1.0], [0.0], [...|\n",
      "|4903|   64|[0.12869413385510...|[[-1.0], [0.0], [...|\n",
      "|3037|   39|[0.11096099499800...|[[-1.0], [0.0], [...|\n",
      "|6486|   88|[0.26171495142384...|[[-1.0], [0.0], [...|\n",
      "|3281|   43|[0.26141455117403...|[[-1.0], [0.0], [...|\n",
      "|7416|   91|[0.22418741898694...|[[-1.0], [-1.0], ...|\n",
      "|1711|   18|[0.18892780931025...|[[-1.0], [0.0], [...|\n",
      "|5319|   71|[0.13585528229187...|[[-1.0], [0.0], [...|\n",
      "|3902|   51|[0.12532757334717...|[[-1.0], [0.0], [...|\n",
      "|7482|   91|[0.13121953945947...|[[-1.0], [0.0], [...|\n",
      "|8515|   96|[0.53328137176629...|[[-1.0], [0.0], [...|\n",
      "|1731|   18|[0.31596215937702...|[[-1.0], [0.0], [...|\n",
      "|2577|   31|[0.10909147291081...|[[0.0], [0.0], [-...|\n",
      "| 651|   10|[0.11777326121969...|[[-1.0], [0.0], [...|\n",
      "|6828|   88|[0.34683763262968...|[[-1.0], [0.0], [...|\n",
      "+----+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The hashed dataset where hashed values are stored in the column 'hashes':\")\n",
    "model.transform(Train_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately joining Train_df and Test_df on Euclidean distance smaller than 1:\n",
      "+--------+-------+------------------+\n",
      "|Train_df|Test_df| EuclideanDistance|\n",
      "+--------+-------+------------------+\n",
      "|     215|   2294|1.0782458048142887|\n",
      "|     215|   5241|0.7923129562535386|\n",
      "|     215|   5318|0.7420657232902292|\n",
      "|     215|   7089|1.0916849915334395|\n",
      "|     215|   7681|1.0382596097039138|\n",
      "|     215|   7946|0.9005270158548503|\n",
      "|     215|   8204|0.9768081522458703|\n",
      "|     215|   8997|0.7807648637175937|\n",
      "|     257|   3749|1.0513798620660821|\n",
      "|     257|   6352|1.0308467022233077|\n",
      "|     257|   8230|0.9955425834271019|\n",
      "|     257|   8236|0.8690752081764956|\n",
      "|     313|   2088|1.0803480397860448|\n",
      "|     313|   7393|1.0644703723857685|\n",
      "|     313|   8361|1.0057352131237303|\n",
      "|     457|    588|0.7221171221826685|\n",
      "|     457|    971|0.7414420055547025|\n",
      "|     457|   1459|0.8981441513005821|\n",
      "|     457|   3024|0.7316857504479307|\n",
      "|     457|   4803|0.7815983736678712|\n",
      "|     457|   5816| 0.613658371912618|\n",
      "|     457|   6985|1.0770916523170286|\n",
      "|     457|   7963|0.6555433893159075|\n",
      "|     457|   8045|0.6289976089344536|\n",
      "|     457|   8068|0.9125573836799837|\n",
      "|     474|   3529|1.0861775554773214|\n",
      "|     474|   6364|1.0936546442867134|\n",
      "|     489|   2713|0.6117201583016475|\n",
      "|     489|   6187|0.5464076479182544|\n",
      "|     489|   7890|0.8485100882409353|\n",
      "+--------+-------+------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Approximately joining Train_df and Test_df on Euclidean distance smaller than 1:\")\n",
    "model.approxSimilarityJoin(Train_df, Test_df, 1.1, distCol=\"EuclideanDistance\")\\\n",
    "    .select(col(\"datasetA.id\").alias(\"Train_df\"),\n",
    "            col(\"datasetB.id\").alias(\"Test_df\"),\n",
    "            col(\"EuclideanDistance\")).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = Vectors.dense(X_test[1][0:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.1597, 0.0502, 0.1769, 0.0376, 0.4228, 0.0528, 0.0885, 0.0116, 0.0922, 0.0625, 0.164, 0.1296, 0.2788, 0.1386, 0.093, 0.0413, 0.1009, 0.0821, 0.1339, 0.1331, 0.3082, 0.0976, 0.0922, 0.0519, 0.0732, 0.0174, 0.1132, 0.0857, 0.4727, 0.1279, 0.1072, 0.0027, 0.1045, 0.0936, 0.1317, 0.1251, 0.2199, 0.134, 0.1147, 0.0765, 0.1263, 0.0644, 0.0856, 0.0861, 0.1933, 0.163, 0.1624, 0.119, 0.1556, 0.1887, 0.156, 0.1087, 0.1117, 0.0686, 0.1045, 0.1062, 0.0501, 0.0504, 0.1413, 0.2452, 0.3666, 0.0595, 0.0606, 0.0262, 0.0852, 0.0366, 0.0582, 0.1093, 0.2926, 0.2241, 0.1324, 0.0616, 0.0812, 0.0528, 0.045, 0.0968, 0.1663, 0.1752, 0.2416, 0.1411, 0.129, 0.1042, 0.082, 0.1547, 0.1944, 0.0854, 0.095, 0.1552, 0.0351, 0.0451, 0.0555, 0.2875, 0.4472, 0.0482, 0.0443, 0.0372, 0.0251, 0.0124, 0.0716, 0.1633, 0.4413, 0.1745, 0.0898, 0.022, 0.0643, 0.0319, 0.0499, 0.0784, 0.2447, 0.2472, 0.1922, 0.0915, 0.1947, 0.0558, 0.054, 0.1193, 0.1361, 0.1386, 0.1436, 0.1578, 0.1023, 0.0826, 0.1048, 0.1792, 0.1848, 0.1207, 0.1238, 0.1018])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately searching Train_df for 2 nearest neighbors of the key:\n"
     ]
    }
   ],
   "source": [
    "print(\"Approximately searching Train_df for 2 nearest neighbors of the key:\")\n",
    "result = model.approxNearestNeighbors(Train_df, key, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4920"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_id = result.select('id',).collect()\n",
    "result_id[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------------------+--------------------+------------------+\n",
      "|  id|label|            features|              hashes|           distCol|\n",
      "+----+-----+--------------------+--------------------+------------------+\n",
      "|4920|   65|[0.06255436828116...|[[-1.0], [-1.0], ...|0.6079006574102186|\n",
      "|1879|   19|[0.02860351989748...|[[-1.0], [0.0], [...|0.6672902776895454|\n",
      "|7264|   89|[0.06820392888503...|[[-1.0], [0.0], [...|0.7119586936622719|\n",
      "|5054|   67|[0.08954207872490...|[[-1.0], [-1.0], ...|0.7162213043250836|\n",
      "|7225|   89|[0.07672373029079...|[[-1.0], [0.0], [...|0.7331880056791682|\n",
      "|3499|   47|[0.16654797336798...|[[-1.0], [0.0], [...|0.7413533417094166|\n",
      "|1863|   19|[0.05745353555556...|[[-1.0], [0.0], [...|0.7422787717680772|\n",
      "|1858|   19|[0.08742506093920...|[[-1.0], [0.0], [...|0.7439794764555937|\n",
      "|3568|   47|[0.13329714694877...|[[-1.0], [0.0], [...|0.7450541728506829|\n",
      "|7296|   90|[0.06964719750357...|[[-1.0], [-1.0], ...|0.7461979146904298|\n",
      "+----+-----+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.pyplot import imshow\n",
    "# imshow(imgs[4795])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
